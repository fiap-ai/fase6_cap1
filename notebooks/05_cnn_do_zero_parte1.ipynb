{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de CNN do Zero - Parte 1: Preparação\n",
    "\n",
    "Este notebook implementa a primeira parte do treinamento de uma Rede Neural Convolucional (CNN) do zero para classificar imagens nas mesmas categorias que usamos nos modelos YOLO. Diferentemente do YOLO, que é um modelo de detecção de objetos, a CNN que vamos treinar é um modelo de classificação de imagens.\n",
    "\n",
    "Nesta primeira parte, vamos focar na preparação dos dados e na definição da arquitetura da CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e configurar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o ambiente já foi configurado\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Se o ambiente ainda não foi configurado, execute o setup_env.sh\n",
    "if not os.path.exists('../yolov5'):\n",
    "    print(\"Configurando o ambiente com setup_env.sh...\")\n",
    "    !chmod +x ../setup_env.sh\n",
    "    !../setup_env.sh\n",
    "else:\n",
    "    print(\"Ambiente já configurado.\")\n",
    "\n",
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "import yaml\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparação dos Dados\n",
    "\n",
    "Vamos preparar os dados para treinamento da CNN. Como a CNN é um modelo de classificação, precisamos adaptar nosso dataset de detecção de objetos para classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo data.yaml para obter as categorias\n",
    "if os.path.exists('../data/data.yaml'):\n",
    "    with open('../data/data.yaml', 'r') as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "    categories = data_yaml['names']\n",
    "    print(f\"Categorias: {categories}\")\n",
    "else:\n",
    "    print(\"Arquivo data.yaml não encontrado. Usando categorias padrão.\")\n",
    "    categories = ['apple', 'banana']\n",
    "\n",
    "# Definir diretórios de dados\n",
    "train_dir = '../dataset/train/images'\n",
    "val_dir = '../dataset/val/images'\n",
    "test_dir = '../dataset/test/images'\n",
    "\n",
    "# Verificar se os diretórios existem\n",
    "for dir_path in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(dir_path):\n",
    "        print(f\"❌ Diretório não encontrado: {dir_path}\")\n",
    "    else:\n",
    "        print(f\"✅ Diretório encontrado: {dir_path}\")\n",
    "        print(f\"   Número de imagens: {len([f for f in os.listdir(dir_path) if f.endswith(('.jpg', '.jpeg', '.png', '.avif'))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Criação de Dataset e DataLoader\n",
    "\n",
    "Vamos criar classes personalizadas para carregar e pré-processar nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformações para as imagens\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Classe personalizada para o dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, categories, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.categories = categories\n",
    "        \n",
    "        # Listar todas as imagens\n",
    "        self.img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.avif'))]\n",
    "        \n",
    "        # Determinar a classe de cada imagem com base no nome do arquivo\n",
    "        self.labels = []\n",
    "        for img_file in self.img_files:\n",
    "            # Assumindo que o nome do arquivo começa com o nome da categoria\n",
    "            # Por exemplo: categoria_a_001.jpg -> categoria_a\n",
    "            for i, category in enumerate(categories):\n",
    "                if category.lower() in img_file.lower():\n",
    "                    self.labels.append(i)\n",
    "                    break\n",
    "            else:\n",
    "                # Se não encontrar a categoria no nome do arquivo, usar a primeira categoria\n",
    "                self.labels.append(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Criar datasets\n",
    "train_dataset = CustomImageDataset(train_dir, categories, transform=train_transforms)\n",
    "val_dataset = CustomImageDataset(val_dir, categories, transform=val_test_transforms)\n",
    "test_dataset = CustomImageDataset(test_dir, categories, transform=val_test_transforms)\n",
    "\n",
    "# Criar dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Verificar os datasets\n",
    "print(f\"Tamanho do dataset de treino: {len(train_dataset)}\")\n",
    "print(f\"Tamanho do dataset de validação: {len(val_dataset)}\")\n",
    "print(f\"Tamanho do dataset de teste: {len(test_dataset)}\")\n",
    "\n",
    "# Verificar a distribuição das classes\n",
    "train_labels = train_dataset.labels\n",
    "val_labels = val_dataset.labels\n",
    "test_labels = test_dataset.labels\n",
    "\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "print(\"Treino:\")\n",
    "for i, category in enumerate(categories):\n",
    "    count = train_labels.count(i)\n",
    "    print(f\"  - {category}: {count} ({count/len(train_labels)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nValidação:\")\n",
    "for i, category in enumerate(categories):\n",
    "    count = val_labels.count(i)\n",
    "    print(f\"  - {category}: {count} ({count/len(val_labels)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTeste:\")\n",
    "for i, category in enumerate(categories):\n",
    "    count = test_labels.count(i)\n",
    "    print(f\"  - {category}: {count} ({count/len(test_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualização de Algumas Imagens\n",
    "\n",
    "Vamos visualizar algumas imagens do dataset para verificar se estão sendo carregadas corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para desnormalizar imagens\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "# Obter algumas imagens do dataset de treino\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Visualizar as imagens\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(min(8, len(images))):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    img = denormalize(images[i])\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{categories[labels[i]]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definição da Arquitetura da CNN\n",
    "\n",
    "Vamos definir a arquitetura da nossa CNN do zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a arquitetura da CNN\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Camadas convolucionais\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Camadas de pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Camadas de batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Camadas fully connected\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Bloco 1\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Bloco 2\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Bloco 3\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Bloco 4\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Criar o modelo\n",
    "model = CustomCNN(num_classes=len(categories))\n",
    "print(model)\n",
    "\n",
    "# Verificar o número de parâmetros\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal de parâmetros: {total_params:,}\")\n",
    "print(f\"Parâmetros treináveis: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Salvando os Dados Preparados\n",
    "\n",
    "Vamos salvar os dados preparados para uso na segunda parte do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diretório para salvar os dados\n",
    "os.makedirs('../models/cnn', exist_ok=True)\n",
    "\n",
    "# Salvar o modelo não treinado\n",
    "torch.save(model.state_dict(), '../models/cnn/cnn_initial.pt')\n",
    "print(\"Modelo inicial salvo em '../models/cnn/cnn_initial.pt'\")\n",
    "\n",
    "# Salvar as categorias\n",
    "with open('../models/cnn/cnn_categories.txt', 'w') as f:\n",
    "    for category in categories:\n",
    "        f.write(f\"{category}\\n\")\n",
    "print(\"Categorias salvas em '../models/cnn/cnn_categories.txt'\")\n",
    "\n",
    "print(\"\\nTudo pronto para o treinamento na Parte 2!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Próximos Passos\n",
    "\n",
    "Na próxima parte (Parte 2), vamos:\n",
    "1. Treinar a CNN do zero\n",
    "2. Avaliar o desempenho do modelo\n",
    "3. Visualizar algumas predições\n",
    "4. Comparar o desempenho com os modelos YOLO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
